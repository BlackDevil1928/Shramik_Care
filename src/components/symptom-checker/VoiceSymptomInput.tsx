'use client';

import React, { useState, useRef } from 'react';
import { motion } from 'framer-motion';
import { symptomMatcher } from '@/lib/symptom-matcher';
import type { Language, SelectedSymptom, VoiceSymptomInput as VoiceInput, ExtractedSymptom } from '@/types/symptom-checker';

interface VoiceSymptomInputProps {
  language: Language;
  onSymptomsExtracted: (symptoms: SelectedSymptom[], transcript: string) => void;
  isKioskMode?: boolean;
}

export default function VoiceSymptomInput({
  language,
  onSymptomsExtracted,
  isKioskMode = false
}: VoiceSymptomInputProps) {
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [isProcessing, setIsProcessing] = useState(false);
  const [extractedSymptoms, setExtractedSymptoms] = useState<ExtractedSymptom[]>([]);
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recognitionRef = useRef<any>(null);

  const translations = {
    en: {
      startRecording: 'Start Recording',
      stopRecording: 'Stop Recording',
      processing: 'Processing...',
      speak: 'Click and speak about your symptoms',
      transcript: 'What you said:',
      foundSymptoms: 'Symptoms detected:',
      noSymptoms: 'No symptoms detected. Try speaking more clearly about how you feel.',
      confirm: 'Confirm Symptoms',
      microphonePermission: 'Please allow microphone access to use voice input.',
      browserNotSupported: 'Voice recording is not supported in your browser.',
      severityEstimate: 'Estimated severity:'
    },
    hi: {
      startRecording: '‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°‡§ø‡§Ç‡§ó ‡§∂‡•Å‡§∞‡•Ç ‡§ï‡§∞‡•á‡§Ç',
      stopRecording: '‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°‡§ø‡§Ç‡§ó ‡§∞‡•ã‡§ï‡•á‡§Ç',
      processing: '‡§™‡•ç‡§∞‡§∏‡§Ç‡§∏‡•ç‡§ï‡§∞‡§£...',
      speak: '‡§ï‡•ç‡§≤‡§ø‡§ï ‡§ï‡§∞‡•á‡§Ç ‡§î‡§∞ ‡§Ö‡§™‡§®‡•á ‡§≤‡§ï‡•ç‡§∑‡§£‡•ã‡§Ç ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§¨‡•ã‡§≤‡•á‡§Ç',
      transcript: '‡§Ü‡§™‡§®‡•á ‡§ú‡•ã ‡§ï‡§π‡§æ:',
      foundSymptoms: '‡§≤‡§ï‡•ç‡§∑‡§£ ‡§Æ‡§ø‡§≤‡•á:',
      noSymptoms: '‡§ï‡•ã‡§à ‡§≤‡§ï‡•ç‡§∑‡§£ ‡§®‡§π‡•Ä‡§Ç ‡§Æ‡§ø‡§≤‡§æ‡•§ ‡§Ö‡§™‡§®‡•á ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§¨‡§æ‡§∞‡•á ‡§Æ‡•á‡§Ç ‡§∏‡•ç‡§™‡§∑‡•ç‡§ü ‡§∞‡•Ç‡§™ ‡§∏‡•á ‡§¨‡•ã‡§≤‡§®‡•á ‡§ï‡•Ä ‡§ï‡•ã‡§∂‡§ø‡§∂ ‡§ï‡§∞‡•á‡§Ç‡•§',
      confirm: '‡§≤‡§ï‡•ç‡§∑‡§£ ‡§™‡•Å‡§∑‡•ç‡§ü‡§ø ‡§ï‡§∞‡•á‡§Ç',
      microphonePermission: '‡§µ‡•â‡§Ø‡§∏ ‡§á‡§®‡§™‡•Å‡§ü ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡§æ‡§á‡§ï‡•ç‡§∞‡•ã‡§´‡§º‡•ã‡§® ‡§è‡§ï‡•ç‡§∏‡•á‡§∏ ‡§ï‡•Ä ‡§Ö‡§®‡•Å‡§Æ‡§§‡§ø ‡§¶‡•á‡§Ç‡•§',
      browserNotSupported: '‡§Ü‡§™‡§ï‡•á ‡§¨‡•ç‡§∞‡§æ‡§â‡§ú‡§º‡§∞ ‡§Æ‡•á‡§Ç ‡§µ‡•â‡§Ø‡§∏ ‡§∞‡§ø‡§ï‡•â‡§∞‡•ç‡§°‡§ø‡§Ç‡§ó ‡§∏‡§Æ‡§∞‡•ç‡§•‡§ø‡§§ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à‡•§',
      severityEstimate: '‡§Ö‡§®‡•Å‡§Æ‡§æ‡§®‡§ø‡§§ ‡§ó‡§Ç‡§≠‡•Ä‡§∞‡§§‡§æ:'
    },
    ml: {
      startRecording: '‡¥±‡µÜ‡¥ï‡µç‡¥ï‡µã‡µº‡¥°‡¥ø‡¥Ç‡¥ó‡µç ‡¥Ü‡¥∞‡¥Ç‡¥≠‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï',
      stopRecording: '‡¥±‡µÜ‡¥ï‡µç‡¥ï‡µã‡µº‡¥°‡¥ø‡¥Ç‡¥ó‡µç ‡¥®‡¥ø‡µº‡¥§‡µç‡¥§‡µÅ‡¥ï',
      processing: '‡¥™‡µç‡¥∞‡µã‡¥∏‡¥∏‡µç‡¥∏‡¥ø‡¥Ç‡¥ó‡µç...',
      speak: '‡¥ï‡µç‡¥≤‡¥ø‡¥ï‡µç‡¥ï‡µç ‡¥ö‡µÜ‡¥Ø‡µç‡¥§‡µç ‡¥®‡¥ø‡¥ô‡µç‡¥ô‡¥≥‡µÅ‡¥ü‡µÜ ‡¥≤‡¥ï‡µç‡¥∑‡¥£‡¥ô‡µç‡¥ô‡¥≥‡µÜ ‡¥ï‡µÅ‡¥±‡¥ø‡¥ö‡µç‡¥ö‡µç ‡¥™‡¥±‡¥Ø‡µÅ‡¥ï',
      transcript: '‡¥®‡¥ø‡¥ô‡µç‡¥ô‡µæ ‡¥™‡¥±‡¥û‡µç‡¥û‡¥§‡µç:',
      foundSymptoms: '‡¥ï‡¥£‡µç‡¥ü‡µÜ‡¥§‡µç‡¥§‡¥ø‡¥Ø ‡¥≤‡¥ï‡µç‡¥∑‡¥£‡¥ô‡µç‡¥ô‡µæ:',
      noSymptoms: '‡¥≤‡¥ï‡µç‡¥∑‡¥£‡¥ô‡µç‡¥ô‡µæ ‡¥ï‡¥£‡µç‡¥ü‡µÜ‡¥§‡µç‡¥§‡¥ø‡¥Ø‡¥ø‡¥≤‡µç‡¥≤. ‡¥®‡¥ø‡¥ô‡µç‡¥ô‡µæ‡¥ï‡µç‡¥ï‡µç ‡¥é‡¥ô‡µç‡¥ô‡¥®‡µÜ ‡¥§‡µã‡¥®‡µç‡¥®‡µÅ‡¥®‡µç‡¥®‡µÅ ‡¥é‡¥®‡µç‡¥®‡¥§‡¥ø‡¥®‡µÜ ‡¥ï‡µÅ‡¥±‡¥ø‡¥ö‡µç‡¥ö‡µç ‡¥ï‡µÇ‡¥ü‡µÅ‡¥§‡µΩ ‡¥µ‡µç‡¥Ø‡¥ï‡µç‡¥§‡¥Æ‡¥æ‡¥Ø‡¥ø ‡¥∏‡¥Ç‡¥∏‡¥æ‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡¥æ‡µª ‡¥∂‡µç‡¥∞‡¥Æ‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï.',
      confirm: '‡¥≤‡¥ï‡µç‡¥∑‡¥£‡¥ô‡µç‡¥ô‡µæ ‡¥∏‡µç‡¥•‡¥ø‡¥∞‡µÄ‡¥ï‡¥∞‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï',
      microphonePermission: '‡¥µ‡µã‡¥Ø‡µç‡¥∏‡µç ‡¥á‡µª‡¥™‡µÅ‡¥ü‡µç‡¥ü‡µç ‡¥â‡¥™‡¥Ø‡µã‡¥ó‡¥ø‡¥ï‡µç‡¥ï‡¥æ‡µª ‡¥Æ‡µà‡¥ï‡µç‡¥∞‡µã‡¥´‡µã‡µ∫ ‡¥Ü‡¥ï‡µç‡¥∏‡¥∏‡µç ‡¥Ö‡¥®‡µÅ‡¥µ‡¥¶‡¥ø‡¥ï‡µç‡¥ï‡µÅ‡¥ï.',
      browserNotSupported: '‡¥®‡¥ø‡¥ô‡µç‡¥ô‡¥≥‡µÅ‡¥ü‡µÜ ‡¥¨‡µç‡¥∞‡µó‡¥∏‡¥±‡¥ø‡µΩ ‡¥µ‡µã‡¥Ø‡µç‡¥∏‡µç ‡¥±‡µÜ‡¥ï‡µç‡¥ï‡µã‡µº‡¥°‡¥ø‡¥Ç‡¥ó‡µç ‡¥™‡¥ø‡¥®‡µç‡¥§‡µÅ‡¥£‡¥Ø‡µç‡¥ï‡µç‡¥ï‡µÅ‡¥®‡µç‡¥®‡¥ø‡¥≤‡µç‡¥≤.',
      severityEstimate: '‡¥ï‡¥£‡¥ï‡µç‡¥ï‡¥æ‡¥ï‡µç‡¥ï‡¥ø‡¥Ø ‡¥§‡µÄ‡¥µ‡µç‡¥∞‡¥§:'
    }
  };

  const t = translations[language as keyof typeof translations] || translations.en;

  const startRecording = async () => {
    try {
      // Request microphone permission
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      
      // Set up Web Speech API if available
      if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
        const SpeechRecognition = (window as any).webkitSpeechRecognition || (window as any).SpeechRecognition;
        const recognition = new SpeechRecognition();
        
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = getLanguageCode(language);
        
        recognition.onresult = (event: any) => {
          let transcript = '';
          for (let i = 0; i < event.results.length; i++) {
            transcript += event.results[i][0].transcript;
          }
          setTranscript(transcript);
        };
        
        recognition.onerror = (event: any) => {
          console.error('Speech recognition error:', event.error);
          setIsRecording(false);
        };
        
        recognition.onend = () => {
          setIsRecording(false);
          if (transcript.trim()) {
            processTranscript(transcript);
          }
        };
        
        recognitionRef.current = recognition;
        recognition.start();
        setIsRecording(true);
      } else {
        // Fallback to basic recording without speech-to-text
        const mediaRecorder = new MediaRecorder(stream);
        mediaRecorderRef.current = mediaRecorder;
        
        mediaRecorder.start();
        setIsRecording(true);
        
        // For demo purposes, simulate transcript after 3 seconds
        setTimeout(() => {
          stopRecording();
          // Simulate some transcript based on language
          const demoTranscript = getDemoTranscript(language);
          setTranscript(demoTranscript);
          processTranscript(demoTranscript);
        }, 3000);
      }
    } catch (error) {
      console.error('Error starting recording:', error);
      alert(t.microphonePermission);
    }
  };

  const stopRecording = () => {
    if (recognitionRef.current) {
      recognitionRef.current.stop();
    }
    if (mediaRecorderRef.current && mediaRecorderRef.current.state === 'recording') {
      mediaRecorderRef.current.stop();
    }
    setIsRecording(false);
  };

  const processTranscript = async (transcriptText: string) => {
    setIsProcessing(true);
    
    // Simulate processing delay
    await new Promise(resolve => setTimeout(resolve, 1000));
    
    const voiceInput: VoiceInput = {
      transcript: transcriptText,
      confidence: 0.85,
      language,
      extractedSymptoms: [],
      timestamp: new Date()
    };
    
    // Extract symptoms using our symptom matcher
    const extracted = symptomMatcher.extractSymptomsFromVoice(voiceInput);
    setExtractedSymptoms(extracted);
    setIsProcessing(false);
  };

  const confirmSymptoms = () => {
    const selectedSymptoms: SelectedSymptom[] = extractedSymptoms.map(symptom => ({
      symptomId: symptom.symptom,
      severity: symptom.severity || 'mild',
      duration: 'days', // Default duration
      onset: 'gradual', // Default onset
      notes: symptom.context
    }));
    
    onSymptomsExtracted(selectedSymptoms, transcript);
  };

  const getLanguageCode = (lang: Language): string => {
    const codes = {
      en: 'en-US',
      hi: 'hi-IN',
      bn: 'bn-BD',
      or: 'or-IN',
      ta: 'ta-IN',
      ne: 'ne-NP',
      ml: 'ml-IN'
    };
    return codes[lang] || 'en-US';
  };

  const getDemoTranscript = (lang: Language): string => {
    const demos = {
      en: "I have a headache and feel very tired. My head is pounding and I feel weak.",
      hi: "‡§Æ‡•á‡§∞‡•á ‡§∏‡§ø‡§∞ ‡§Æ‡•á‡§Ç ‡§¶‡§∞‡•ç‡§¶ ‡§π‡•à ‡§î‡§∞ ‡§Æ‡•à‡§Ç ‡§¨‡§π‡•Å‡§§ ‡§•‡§ï‡§æ ‡§π‡•Å‡§Ü ‡§Æ‡§π‡§∏‡•Ç‡§∏ ‡§ï‡§∞ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Ç‡•§",
      bn: "‡¶Ü‡¶Æ‡¶æ‡¶∞ ‡¶Æ‡¶æ‡¶•‡¶æ‡¶¨‡ßç‡¶Ø‡¶•‡¶æ ‡¶è‡¶¨‡¶Ç ‡¶ñ‡ßÅ‡¶¨ ‡¶ï‡ßç‡¶≤‡¶æ‡¶®‡ßç‡¶§ ‡¶≤‡¶æ‡¶ó‡¶õ‡ßá‡•§",
      or: "‡¨Æ‡≠ã‡¨∞ ‡¨Æ‡≠Å‡¨£‡≠ç‡¨° ‡¨¨‡≠ç‡≠ü‡¨•‡¨æ ‡¨è‡¨¨‡¨Ç ‡¨¨‡¨π‡≠Å‡¨§ ‡¨ï‡≠ç‡¨≤‡¨æ‡¨®‡≠ç‡¨§ ‡¨≤‡¨æ‡¨ó‡≠Å‡¨õ‡¨ø‡•§",
      ta: "‡Æé‡Æ©‡Æï‡Øç‡Æï‡ØÅ ‡Æ§‡Æ≤‡Øà‡Æµ‡Æ≤‡Æø ‡ÆÆ‡Æ±‡Øç‡Æ±‡ØÅ‡ÆÆ‡Øç ‡ÆÆ‡Æø‡Æï‡Æµ‡ØÅ‡ÆÆ‡Øç ‡Æö‡Øã‡Æ∞‡Øç‡Æµ‡Ææ‡Æï ‡Æâ‡Æ£‡Æ∞‡Øç‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç‡•§",
      ne: "‡§Æ‡•á‡§∞‡•ã ‡§ü‡§æ‡§â‡§ï‡•ã ‡§¶‡•Å‡§ñ‡•ç‡§õ ‡§∞ ‡§ß‡•á‡§∞‡•à ‡§•‡§ï‡§æ‡§® ‡§≤‡§æ‡§ó‡•ç‡§õ‡•§",
      ml: "‡¥é‡¥®‡¥ø‡¥ï‡µç‡¥ï‡µç ‡¥§‡¥≤‡¥µ‡µá‡¥¶‡¥®‡¥Ø‡µÅ‡¥Ç ‡¥µ‡¥≥‡¥∞‡µÜ ‡¥ï‡µç‡¥∑‡µÄ‡¥£‡¥µ‡µÅ‡¥Ç ‡¥Ö‡¥®‡µÅ‡¥≠‡¥µ‡¥™‡µç‡¥™‡µÜ‡¥ü‡µÅ‡¥®‡µç‡¥®‡µÅ‡•§"
    };
    return demos[lang] || demos.en;
  };

  const getSeverityColor = (severity: string) => {
    switch (severity) {
      case 'mild': return 'text-green-600';
      case 'moderate': return 'text-yellow-600';
      case 'severe': return 'text-orange-600';
      case 'critical': return 'text-red-600';
      default: return 'text-gray-600';
    }
  };

  return (
    <div className="bg-white rounded-2xl p-6 shadow-lg border">
      {/* Voice Recording Button */}
      <div className="text-center mb-6">
        <motion.button
          onClick={isRecording ? stopRecording : startRecording}
          disabled={isProcessing}
          className={`
            ${isKioskMode ? 'w-32 h-32' : 'w-24 h-24'} 
            rounded-full shadow-lg transition-all duration-300 text-white font-semibold
            ${isRecording 
              ? 'bg-red-500 hover:bg-red-600 animate-pulse' 
              : 'bg-kerala-teal hover:bg-kerala-teal/90'
            }
            ${isProcessing ? 'opacity-50 cursor-not-allowed' : 'hover:scale-105'}
          `}
          whileHover={{ scale: isProcessing ? 1 : 1.05 }}
          whileTap={{ scale: 0.95 }}
        >
          {isProcessing ? (
            <div className="animate-spin">‚öôÔ∏è</div>
          ) : (
            <div className={`${isKioskMode ? 'text-4xl' : 'text-3xl'}`}>
              {isRecording ? 'üõë' : 'üé§'}
            </div>
          )}
        </motion.button>
        
        <p className={`mt-4 text-gray-600 ${isKioskMode ? 'text-lg' : 'text-base'}`}>
          {isProcessing ? t.processing : isRecording ? t.stopRecording : t.speak}
        </p>
      </div>

      {/* Transcript Display */}
      {transcript && (
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={{ opacity: 1, y: 0 }}
          className="mb-6 p-4 bg-blue-50 rounded-lg"
        >
          <h4 className={`font-medium text-blue-900 mb-2 ${isKioskMode ? 'text-lg' : 'text-base'}`}>
            {t.transcript}
          </h4>
          <p className={`text-blue-800 ${isKioskMode ? 'text-base' : 'text-sm'}`}>
            "{transcript}"
          </p>
        </motion.div>
      )}

      {/* Extracted Symptoms */}
      {extractedSymptoms.length > 0 && (
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={{ opacity: 1, y: 0 }}
          className="mb-6"
        >
          <h4 className={`font-medium text-gray-900 mb-3 ${isKioskMode ? 'text-lg' : 'text-base'}`}>
            {t.foundSymptoms}
          </h4>
          <div className="space-y-2">
            {extractedSymptoms.map((symptom, index) => {
              const symptomData = symptomMatcher.getSymptomById(symptom.symptom);
              return (
                <div key={index} className="flex items-center justify-between p-3 bg-green-50 rounded-lg">
                  <div>
                    <span className={`font-medium ${isKioskMode ? 'text-base' : 'text-sm'}`}>
                      {symptomData?.icon} {symptomData?.name[language] || symptomData?.name.en}
                    </span>
                    {symptom.severity && (
                      <span className={`ml-2 text-xs px-2 py-1 rounded-full ${getSeverityColor(symptom.severity)} bg-white`}>
                        {t.severityEstimate} {symptom.severity}
                      </span>
                    )}
                  </div>
                  <div className={`text-xs text-gray-500 ${isKioskMode ? 'text-sm' : ''}`}>
                    {Math.round(symptom.confidence * 100)}% confident
                  </div>
                </div>
              );
            })}
          </div>
          
          <motion.button
            onClick={confirmSymptoms}
            className={`
              mt-4 w-full py-3 bg-green-600 text-white rounded-lg hover:bg-green-700 
              transition-colors font-semibold
              ${isKioskMode ? 'text-lg' : 'text-base'}
            `}
            whileHover={{ scale: 1.02 }}
            whileTap={{ scale: 0.98 }}
          >
            {t.confirm} ({extractedSymptoms.length})
          </motion.button>
        </motion.div>
      )}

      {/* No Symptoms Message */}
      {transcript && !isProcessing && extractedSymptoms.length === 0 && (
        <motion.div
          initial={{ opacity: 0, y: 20 }}
          animate={{ opacity: 1, y: 0 }}
          className="p-4 bg-yellow-50 rounded-lg text-center"
        >
          <p className={`text-yellow-800 ${isKioskMode ? 'text-base' : 'text-sm'}`}>
            {t.noSymptoms}
          </p>
        </motion.div>
      )}

      {/* Browser Support Check */}
      {!('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) && (
        <div className="mt-4 p-3 bg-orange-50 rounded-lg text-center">
          <p className={`text-orange-800 ${isKioskMode ? 'text-base' : 'text-sm'}`}>
            {t.browserNotSupported}
          </p>
        </div>
      )}
    </div>
  );
}